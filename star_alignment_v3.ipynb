{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import traceback\n",
    "import argparse\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893faafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarAligner:        \n",
    "    def merged_reads(self, runThreadN, merged, star_index, processed_folder):\n",
    "        \"\"\"\n",
    "        Align single-end reads (merged)\n",
    "        \"\"\"\n",
    "        merged_str = \",\".join(merged)\n",
    "        prefix = processed_folder/\"merged\"\n",
    "        \n",
    "        try:\n",
    "            cmd = [\"STAR\", \"--runThreadN\", str(runThreadN),\n",
    "                   \"--runMode\", \"alignReads\",\n",
    "                   \"--readFilesIn\", str(merged_str),\n",
    "                   \"--readFilesCommand\", \"gunzip\", \"-c\",\n",
    "                   \"--genomeDir\", str(star_index),\n",
    "                   \"--outFileNamePrefix\", str(prefix),\n",
    "                   \"--outSAMtype\", \"BAM\", \"SortedByCoordinate\",\n",
    "                   \"--outFilterType\", \"BySJout\",\n",
    "                   \"--outSAMattributes\", \"NH\", \"NM\", \"AS\", \"MD\"]\n",
    "            result = subprocess.run(cmd, \n",
    "                                    check = True, \n",
    "                                    capture_output = True, \n",
    "                                    text = True)\n",
    "        except subprocess.CalledProcessError as e: ## error handling\n",
    "            print(f\"Failed to align merged fastqs with STAR: {e}\")\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "        return result\n",
    "\n",
    "    def unpaired_reads(self, runThreadN, unpaired_r1, unpaired_r2, star_index, processed_folder):\n",
    "        \"\"\"\n",
    "        Align single-end reads (unpaired)\n",
    "        \"\"\"\n",
    "        r1_str = \",\".join(unpaired_r1)\n",
    "        r2_str = \",\".join(unpaired_r2)\n",
    "        prefix_1 = processed_folder/\"unpaired_r1\"\n",
    "        prefix_2 = processed_folder/\"unpaired_r2\"\n",
    "        \n",
    "        try:\n",
    "            cmd_1 = [\"STAR\", \"--runThreadN\", str(runThreadN),\n",
    "                     \"--runMode\", \"alignReads\",\n",
    "                     \"--readFilesIn\", str(r1_str),\n",
    "                     \"--readFilesCommand\", \"gunzip\", \"-c\",\n",
    "                     \"--genomeDir\", str(star_index),\n",
    "                     \"--outFileNamePrefix\", str(prefix_1),\n",
    "                     \"--outSAMtype\", \"BAM\", \"SortedByCoordinate\",\n",
    "                     \"--outFilterType\", \"BySJout\",\n",
    "                     \"--outSAMattributes\", \"NH\", \"NM\", \"AS\", \"MD\"]\n",
    "            cmd_2 = [\"STAR\", \"--runThreadN\", str(runThreadN),\n",
    "                     \"--runMode\", \"alignReads\",\n",
    "                     \"--readFilesIn\", str(r2_str),\n",
    "                     \"--readFilesCommand\", \"gunzip\", \"-c\",\n",
    "                     \"--genomeDir\", str(star_index),\n",
    "                     \"--outFileNamePrefix\", str(prefix_2),\n",
    "                     \"--outSAMtype\", \"BAM\", \"SortedByCoordinate\",\n",
    "                     \"--outFilterType\", \"BySJout\",\n",
    "                     \"--outSAMattributes\", \"NH\", \"NM\", \"AS\", \"MD\"]\n",
    "            subprocess.run(cmd_1, \n",
    "                           check = True, \n",
    "                           capture_output = True, \n",
    "                           text = True)\n",
    "            subprocess.run(cmd_2, \n",
    "                           check = True, \n",
    "                           capture_output = True, \n",
    "                           text = True)\n",
    "        except subprocess.CalledProcessError as e: ## error handling\n",
    "            print(f\"Failed to align unpaired fastqs with STAR: {e}\")\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "\n",
    "    def paired_reads(self, runThreadN, paired_r1, paired_r2, star_index, processed_folder):\n",
    "        \"\"\"\n",
    "        Align paired-end reads (unmerged)\n",
    "        \"\"\"\n",
    "        r1_str = \",\".join(paired_r1)\n",
    "        r2_str = \",\".join(paired_r2)\n",
    "        prefix = processed_folder/\"paired\"\n",
    "\n",
    "        try:\n",
    "            cmd = [\"STAR\", \"--runThreadN\", str(runThreadN),\n",
    "                   \"--runMode\", \"alignReads\",\n",
    "                   \"--readFilesIn\", str(r1_str), str(r2_str),\n",
    "                   \"--readFilesCommand\", \"gunzip\", \"-c\",\n",
    "                   \"--genomeDir\", str(star_index),\n",
    "                   \"--outFileNamePrefix\", str(prefix),\n",
    "                   \"--outSAMtype\", \"BAM\", \"SortedByCoordinate\",\n",
    "                   \"--outFilterType\", \"BySJout\",\n",
    "                   \"--outSAMattributes\", \"NH\", \"NM\", \"AS\", \"MD\"]\n",
    "            result = subprocess.run(cmd, \n",
    "                                    check = True, \n",
    "                                    capture_output = True, \n",
    "                                    text = True)\n",
    "        except subprocess.CalledProcessError as e: ## error handling\n",
    "            print(f\"Failed to align unmerged fastq files: {e}\")\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "        return result\n",
    "    \n",
    "    def tagXSstrandedData(self, awk_dir):\n",
    "        \"\"\"\n",
    "        Add XS tags to every read in a stranded .bam file\n",
    "        \"\"\"\n",
    "        self.sam_file = f\"{self.merged_bam.rpartition(\".\")[0]}.sam\"\n",
    "\n",
    "        try:\n",
    "            file = subprocess.run([\"samtools\", \"view\", ## open up merged .bam\n",
    "                                    \"-h\", str(self.merged_bam)],\n",
    "                                    stdout = subprocess.PIPE,\n",
    "                                    check = True)\n",
    "            with open(self.sam_file, \"w\") as out_f:\n",
    "                subprocess.run([\"awk\", \"-v\", \"strType=2\", ## run awk script\n",
    "                                \"-f\", str(awk_dir)],\n",
    "                                input = file.stdout, \n",
    "                                stdout = out_f,\n",
    "                                check = True)\n",
    "            subprocess.run([\"rm\", str(self.merged_bam)],\n",
    "                            check = True, \n",
    "                            capture_output = True)\n",
    "        except subprocess.CalledProcessError as e: ## error handling\n",
    "            print(f\"Failed to add XS tags to {self.merged_bam.name}: {e}\")\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "\n",
    "    def convert_sam(self):\n",
    "        \"\"\"\n",
    "        Converts .sam output from XS tagging into .bam\n",
    "        \"\"\"\n",
    "        try:\n",
    "            subprocess.run([\"samtools\", \"sort\", \"-O\", \"BAM\",\n",
    "                            \"-o\", str(self.merged_bam),\n",
    "                            str(self.sam_file)],\n",
    "                            check = True,\n",
    "                            capture_output = True,\n",
    "                            text = True)\n",
    "        except subprocess.CalledProcessError as e: ## error handling\n",
    "            print(f\"Failed to convert {self.sam_file.name} to .bam: {e}\")\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "    \n",
    "    def merge_bam(self, processed_folder, subfolder, awk_dir):\n",
    "        \"\"\"\n",
    "        Merge all .bam files, then \n",
    "        sort and index into .bai\n",
    "        \"\"\"\n",
    "        self.merged_bam = processed_folder/f\"{subfolder.name}.bam\"\n",
    "        bam_list = [*processed_folder.glob(\"*out.bam\")] # detect .bam files\n",
    "        rm_list = [*processed_folder.glob(\"*out.bam\"), *processed_folder.glob(\"*.sam\")]\n",
    "\n",
    "        try:\n",
    "            subprocess.run([\"samtools\", \"merge\", ## merge all .bam files into one\n",
    "                            str(self.merged_bam), *map(str, bam_list)],\n",
    "                            check = True, \n",
    "                            capture_output = True,\n",
    "                            text = True)\n",
    "            self.tagXSstrandedData(awk_dir)\n",
    "            self.convert_sam()\n",
    "            subprocess.run([\"samtools\", \"index\", str(self.merged_bam)], ## create .bai from .bam\n",
    "                            check = True,\n",
    "                            capture_output = True,\n",
    "                            text = True)\n",
    "            subprocess.run([\"rm\", *map(str, rm_list)], ## remove original .bam files\n",
    "                            check = True,\n",
    "                            capture_output = True,\n",
    "                            text = True)\n",
    "        except subprocess.CalledProcessError as e: ## error handling\n",
    "            print(f\"Failed to create {self.merged_bam.name} and convert to .bai: {e}\")\n",
    "            print(\"STDERR:\", e.stderr)\n",
    "            print(\"STDOUT:\", e.stdout)\n",
    "            traceback.print_exc()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODIFIED CODE FROM run_hisat2.py\n",
    "\n",
    "def complement_base(base):\n",
    "    \"\"\"\n",
    "    Return complement of a single DNA base\n",
    "    \"\"\"\n",
    "    if base == \"A\":\n",
    "        return \"T\"\n",
    "    elif base == \"T\":\n",
    "        return \"A\"\n",
    "    elif base == \"C\":\n",
    "        return \"G\"\n",
    "    elif base == \"G\":\n",
    "        return \"C\"\n",
    "    else:\n",
    "        return base\n",
    "    \n",
    "def reverse_complement_fastq(file, output):\n",
    "    \"\"\"\n",
    "    Manually reverse complement unpaired R2 fastq.gz file\n",
    "    \"\"\"\n",
    "    # Decompress input fastq.gz file using gunzip\n",
    "    file = Path(file)\n",
    "    output = Path(output)\n",
    "    unzipped_file = file.with_suffix(\"\")\n",
    "    \n",
    "    try:        \n",
    "        if not unzipped_file.exists():\n",
    "            subprocess.run([\"gunzip\", \"-k\", str(file)],\n",
    "                            check = True,\n",
    "                            capture_output = True,\n",
    "                            text = True)\n",
    "\n",
    "        # Open file and reverse complement bases\n",
    "        with open(unzipped_file, \"r\") as input_file, open(output, \"w\") as output_file:\n",
    "            for i, line in enumerate(input_file):\n",
    "                if i % 4 == 1:\n",
    "                    # Reverse complement sequence\n",
    "                    sequence = line.strip()\n",
    "                    reverse_complement = \"\".join([complement_base(base) for base in sequence[::-1]])\n",
    "                    output_file.write(reverse_complement + \"\\n\")\n",
    "                elif i % 4 == 3: \n",
    "                    # Reverse quality scores\n",
    "                    quality_scores = line.strip()\n",
    "                    output_file.write(quality_scores[::-1] + \"\\n\") \n",
    "                else:  \n",
    "                    # Non-sequence and non-quality score lines\n",
    "                    output_file.write(line)\n",
    "\n",
    "        subprocess.run([\"gzip\", str(output)],\n",
    "                        check = True,\n",
    "                        capture_output = True,\n",
    "                        text = True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to create output fastq {output}: {e}\")\n",
    "        print(\"STDERR:\", e.stderr)\n",
    "        print(\"STDOUT:\", e.stdout)\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "    if unzipped_file.exists():\n",
    "        unzipped_file.unlink()\n",
    "\n",
    "## MODIFIED CODE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_files(subfolder, match_pattern, list):\n",
    "    for i in subfolder.glob(match_pattern): ## used for finding files and appending them to a list; avoids redundant for loop later\n",
    "        str_name = str(i)\n",
    "        list.append(str_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a962fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_pipeline(folder_name, genomeDir, runThreadN):\n",
    "    current_path = Path.cwd()\n",
    "    input_dir = current_path/folder_name\n",
    "    input_name = input_dir.name\n",
    "    star_index = Path(genomeDir)\n",
    "    awk_dir = current_path/\"tagXSstrandedData.awk\"\n",
    "\n",
    "    ## initialize class\n",
    "    aligner = StarAligner()\n",
    "\n",
    "    for subfolder in input_dir.iterdir(): ## amount of subfolders = number of replicates\n",
    "        if subfolder.is_dir():\n",
    "            merged = []\n",
    "            unpaired_r1 = []\n",
    "            unpaired_r2 = []\n",
    "            paired_r1 = []\n",
    "            paired_r2 = []\n",
    "            processed_folder = current_path/\"alignments\"/input_name/f\"{subfolder.name}_star\"\n",
    "            processed_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            for file in subfolder.glob(\"*.fastq.gz\"): ## iterate through files and add to corresponding lsits\n",
    "                try:\n",
    "                    ## run star alignment functions\n",
    "                    if \"_merged\" in file.name:\n",
    "                        collect_files(subfolder, \"*_merged*\", merged)\n",
    "                    elif \"_unpaired\" in file.name:\n",
    "                        if \"_unpaired_R2\" in file.name:\n",
    "                            output = file.with_name(file.name.replace(\"_unpaired_\", \"_unpairedrc_\"))\n",
    "                            output_fastq = output.with_suffix(\"\")\n",
    "                            reverse_complement_fastq(file, output_fastq)\n",
    "                            for r1_file in subfolder.glob(\"*_unpaired_R1*\"):\n",
    "                                r1_str_name = str(r1_file)\n",
    "                                r2_str_name = str(output_fastq) + \".gz\"\n",
    "                                unpaired_r1.append(r1_str_name)\n",
    "                                unpaired_r2.append(r2_str_name)\n",
    "                    elif \"_unmerged\" in file.name:\n",
    "                        for r1_file in subfolder.glob(\"*_unmerged_R1*\"):\n",
    "                            r1_str_name = str(r1_file)\n",
    "                            r2_file = r1_file.with_name(r1_file.name.replace(\"_R1_\", \"_R2_\"))\n",
    "                            r2_str_name = str(r2_file)\n",
    "                            paired_r1.append(r1_str_name)\n",
    "                            paired_r2.append(r2_str_name)           \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to align {file.name} with STAR and produce .bam files: {e}\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "            \n",
    "            ## run star alignment\n",
    "            aligner.merged_reads(runThreadN, merged, star_index, processed_folder)\n",
    "            aligner.unpaired_reads(runThreadN, unpaired_r1, unpaired_r2, star_index, processed_folder)\n",
    "            aligner.paired_reads(runThreadN, paired_r1, paired_r2, star_index, processed_folder) \n",
    "\n",
    "            ## merge bam files, convert to bai, & remove old files\n",
    "            aligner.merge_bam(processed_folder, subfolder, awk_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39913ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description = \"Runs STAR alignment.\")\n",
    "    parser.add_argument(\"--input\", help = \"Path to directory with merged, paired, and unpaired fastqs\", required = True)\n",
    "    parser.add_argument(\"--genomeDir\", help = \"Path to genome index\", required = True)\n",
    "    parser.add_argument(\"--runThreadN\", type = int, default = 8, help = \"Number of CPU cores (default: 12)\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Starting STAR alignment pipeline...\")\n",
    "    star_pipeline(args.input, args.genomeDir, args.runThreadN)\n",
    "    print(\"Pipeline finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
